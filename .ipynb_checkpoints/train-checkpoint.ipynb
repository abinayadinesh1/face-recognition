{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2419cbcd-76a1-4067-9267-c82d970ab1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face-recognition\n",
      "  Using cached face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting face-recognition-models>=0.3.0 (from face-recognition)\n",
      "  Using cached face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: Click>=6.0 in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from face-recognition) (8.0.4)\n",
      "Collecting dlib>=19.7 (from face-recognition)\n",
      "  Using cached dlib-19.24.2.tar.gz (11.8 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from face-recognition) (1.24.3)\n",
      "Requirement already satisfied: Pillow in /Users/abinayadinesh/opt/anaconda3/lib/python3.9/site-packages (from face-recognition) (9.4.0)\n",
      "Building wheels for collected packages: dlib, face-recognition-models\n",
      "  Building wheel for dlib (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dlib: filename=dlib-19.24.2-cp39-cp39-macosx_13_0_x86_64.whl size=3853065 sha256=c6d2b87c86727b82da2d8e51cd66f0afb0f3dbd31f209d28356c1fda302e7f99\n",
      "  Stored in directory: /Users/abinayadinesh/Library/Caches/pip/wheels/f7/ae/0e/3478eae12f6aed0e3d4880147ca855ba5d58f2e1098c73ab5f\n",
      "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566171 sha256=bc46923a49beacfea3c6d855c92c9f01325267a26e8e69624a84d630f3d9bcf9\n",
      "  Stored in directory: /Users/abinayadinesh/Library/Caches/pip/wheels/22/a8/60/4a2aeb763d63f50190f4c4e07069a22245347eeafdb3a67551\n",
      "Successfully built dlib face-recognition-models\n",
      "Installing collected packages: face-recognition-models, dlib, face-recognition\n",
      "Successfully installed dlib-19.24.2 face-recognition-1.3.0 face-recognition-models-0.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install face-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64d3ebe8-e01b-4a6a-a1c1-0cd9d9de044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010a00ec-7e82-4a87-9b26-6c6037faf537",
   "metadata": {},
   "source": [
    "1. find all faces in the image\n",
    "2. get the embeddings for all of them\n",
    "3. compare each embedding to the embedding u are looking for (target person)\n",
    "4. make a bounding box around that person (to get their x, y coordinates)\n",
    "5. depending on the x, y coordinates, update spot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "956a0820-6a37-41fa-ad74-dcde29c5badc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bde84e98-aef6-4b4b-a9e9-8baa6b04eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store ur target image and embeddings\n",
    "inga = face_recognition.load_image_file(\"inga.png\")\n",
    "inga_embedded = face_recognition.face_encodings(inga)[0]\n",
    "abi = face_recognition.load_image_file(\"abi.png\")\n",
    "abi_embedded = face_recognition.face_encodings(abi)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d5326f-20da-4abc-a64e-e31f3f81036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_encodings = [abi_embedded, inga_embedded]\n",
    "known_names = [\"abi\", \"inga\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "490100b8-1d79-4bb1-91fc-7ffb00d6338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f959dcb-0fda-4ad6-9c51-4c1ea77cedb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get locations of all faces in ur image and get encodings for each of those faces\n",
    "unknown_image = face_recognition.load_image_file(\"test.jpg\")\n",
    "face_locations = face_recognition.face_locations(unknown_image)\n",
    "face_encodings = face_recognition.face_encodings(unknown_image, face_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8153676a-15a2-4ff8-a151-8acfb3bec7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for face_encoding in face_encodings:\n",
    "    matches = face_recognition.compare_faces(face_encodings, face_encoding)\n",
    "    name = \"Unknown\"\n",
    "    \n",
    "    face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "    best_match_index = np.argmin(face_distances)\n",
    "    if matches[best_match_index]:\n",
    "        name = known_names[best_match_index]\n",
    "\n",
    "    face_names.append(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38f5944-75ec-469f-ab65-8ed514313292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all faces in the picture and get embeddings for them\n",
    "\n",
    "face_locations = face_recognition.face_locations(unknown_image)\n",
    "face_encodings = face_recognition.face_encodings(unknown_image, face_locations)\n",
    "# results = face_recognition.compare_faces([known_encoding], unknown_encoding)\n",
    "\n",
    "\n",
    "for location in face_location:\n",
    "        \n",
    "unknown_encoding = face_recognition.face_encodings(unknown_image)[0]\n",
    "\n",
    "\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "print(face_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f08e7b7-561d-423d-b3b5-b0d9233882c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c145df3-3cf6-47c1-bc8a-500f29b48718",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_landmarks_list = face_recognition.face_landmarks(image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
